---
title: 模式识别 第三章 概率密度函数的估计
date: 2017-03-26 18:47:49
categories: ML/卢晓春 模式识别引论
mathjax: true
tags: [Machine Learning]
---
<!--more-->

## 第三章 概率密度函数的估计
比贝叶斯决策多了估算**先验概率和类条件概率密度函数**
在实际中先验概率和类条件概率密度函数常常是未知的。设计分类器的过程一般分为两步，称为基于样本的两步贝叶斯决策。
>* 利用样本集估计类条件概率密度与先验概率
* 将估计量代入贝叶斯决策规则，完成分类器设计


在统计学上，有以下几个常用标准和概念：
> 
* 无偏性：参数x的估计量$(x_1,x_2..x_n)$的数学期望等于x，则称估计是无偏的，当样本数趋于无穷时才有的无偏性称为渐进无偏
* 有效性：方差更小的估计，更有效
* 一致性：如果有 $\lim\limits_{n\to\infty}P(|\hat x - x|>\epsilon)=0$，则称为一致估计
* 点估计、区间估计。统计量、参数空间、基于平均和方差的评价

整体思路：
> * 如何利用样本集估计$\hat p(x|w_i)$和$\hat p(w_i)$
    * 在典型的有监督模式识别问题中，估计先验概率较为简单。
    * 类条件概率密度估计难度在于：一般来说，训练样本总数较少；x的维数较大时，存在计算复杂度等问题。
    * 从样本集推断总体概率分布的方法可以归纳为2种
        * 参数估计：总体概率密度函数形式已知，但某些参数未知。
            * 监督参数估计：样本所属类别已知
            * 非监督参数估计：未知样本类别
        * 非参数估计：已知样本类别，未知总体概率密度函数形式，要求直接推断概率密度函数本身。
* 估计量的性质如何
* 利用样本集估计错误率的方法


### 最大似然估计(一般用这个)
待估计参数被看做是确定性的，取值未知的量。最佳估计就是使得产生已观测到的样本的概率为最大的那个值。
![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-e80b89b29e0a57ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

例子：
> ![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-308962cd2af36794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
> ![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-6d513642a3a4e08a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
> ![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-5ceb75ca1ad43738.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
> ![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-751f648acd706902.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 贝叶斯估计
把待估计参数看做是符合某种先验概率分布的随机变量。对样本进行观测的过程，就是把先验概率密度转换为后验概率密度，使用样本信息修正对参数的估计值。
贝叶斯决策与贝叶斯估计两者都是立足于使贝叶斯风险最小，只是要解决的问题不同，前者是要**决策x的真实状态**，而后者则是要**估计X所属总体分布的参数**。


### 对比总结
* 贝叶斯估计方法有很强的理论和算法基础，但在实际应用中，最大似然估计更为简便。
* 用本章介绍的估计结果以及第二章贝叶斯决策来设计分类器时，最终系统误差来源可能如下
    * 贝叶斯误差：由p(x|ωi)之间的互相重叠造成，不可消除。
    * 模型误差：选择了不正确的模型导致。可消除设计者根据对问题的先验知识和理解来选择模型
    * 估计误差：采用有限样本进行估计造成的误差。可以通过增加样本个数来减小。



---
title: CS229 Week6 评估&设计
date: 2017-03-26 18:43:18
categories: ML/CS229
mathjax: false
tags: [Machine Learning,CS229]
---
<!--more-->


# 第六周 
## 10 Advice for Applying Machine Learning
### 10.1 决定下一步做什么
当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？:
>1. 获得更多的训练实例——通常是有效的，但代价较大，下面的方法也可能有效，可
考虑先采用下面的几种方法。
2. 尝试减少特征的数量
3. 尝试获得更多的特征
4. 尝试增加多项式特征
5. 尝试减少归一化程度 λ
6. 尝试增加归一化程度 λ

### 10.2 评估一个假设
把样本数据分为训练集、测试集，以此来评估模型。
### 10.3 模型选择和交叉验证集
假设我们要在 10 个不同次数的二项式模型之间进行选择，
我们需要使用 60%的数据作为训练集，使用20%的数据作为交叉验证集， 使用 20%的数据作为测试集。
模型选择的方法为：
>1. 使用训练集训练出 10 个模型
2. 用 10 个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）
3. 选取代价函数值最小的模型
4. 用步骤 3 中选出的模型对测试集计算得出推广误差（代价函数的值）

### 10.4 诊断偏差和方差
>![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-c4f708253fcdeaf6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
>
* 对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着 d 的增长，拟合程度提高，误差减小。
* 对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。
    * 训练集误差和交叉验证集误差近似时： 偏差/欠拟合
    * 交叉验证集误差远大于训练集误差时： 方差/过拟合

### 10.5 归一化和偏差/方差
选择 λ 的方法为：
>1. 使用训练集训练出 12 个不同程度归一化的模型
2. 用 12 模型分别对交叉验证集计算的出交叉验证误差
3. 选择得出交叉验证误差最小的模型
4. 运用步骤 3 中选出模型对测试集计算得出推广误差，我们也可以同时将训练集交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：
    * 当 λ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大
    * 随着 λ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加
    ![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-70d62c1e6a6b63e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 10.6 学习曲线
学习曲线：训练集误差和交叉验证集误差作为训练集实例数量（ m）的函数绘制的图表
应用：
>* 在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助
![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-428acf512968ad71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
* 利用学习曲线识别高方差/过拟合：
当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-98a19a6a5c11a23d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


### 10.7 决定下一步做什么
>1. 获得更多的训练实例——解决高方差
2. 尝试减少特征的数量——解决高方差
3. 尝试获得更多的特征——解决高偏差
4. 尝试增加多项式特征——解决高偏差
5. 尝试减少归一化程度 λ——解决高偏差
6. 尝试增加归一化程度 λ——解决高方差

* 使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小
* 使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过归一化手段来调整而更加适应数据。
* 通常选择较大的神经网络并采用归一化处理会比采用较小的神经网络效果要好。
* 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，然后选择交叉验证集代价最小的神经网络

## 11 机器学习系统的设计(Machine Learning System Design)
### 11.1 首先要做什么
列出可能的方向：当我们使用机器学习时，总是可以“头脑风暴”一下，想出一堆方法来
试试。在11.2会教导如何更可能地选择一个真正的好方法，然后花精力去研究。
### 11.2 误差分析error analysis
选出正确的方向：
**构建一个学习算法的推荐方法为：**
>1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法
2. 绘制**学习曲线**，决定是增加更多数据，或者添加更多特征，还是其他选择
3. 进行**误差分析**：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势（然后从出现次数最多的情况开始着手优化）
4. 误差分析并不总能帮助我们判断应该采取怎样的行动。有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看**交叉验证**集的误差。

### 11.3 类偏斜的误差度量Error Metrics for Skewed Classes
类偏斜情况：表现为我们的训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例。
因为样本的偏差，所有误差分析此时不能作为评判算法的标准，因此提出另一方法来作为**偏斜类问题的评估度量值**
查准率（Precision）和查全率（Recall）我们将算法预测的结果分成四种情况：
>1. 正确肯定（ True Positive,TP）：预测为真，实际为真
2. 正确否定（ True Negative,TN）：预测为假，实际为假
3. 错误肯定（ False Positive,FP）：预测为真，实际为假
4. 错误否定（ False Negative,FN）：预测为假，实际为真
则：
**查准率=TP/（ TP+FP）**例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。
**查全率=TP/（ TP+FN）**例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。

### 11.4 查全率和查准率之间的权衡
|目的|方法|结果|
|:-:|:-:|:-:|
|**更高的查准率**|使用比 0.5 更大的阀值，如 0.7， 0.9|减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。|
|**提高查全率**|使用比 0.5 更小的阀值，如 0.3|尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以。|
**查全率与查准率的关系：**
>![Paste_Image.png](http://upload-images.jianshu.io/upload_images/2812342-30277b772290b15b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
$F_{1}Score=\frac{PR}{P+R}$

### 11.5 机器学习的数据
在机器学习中的普遍共识： "取得成功的人不是拥有最好算法的人， 而是拥有最多数据的人"。
**关键的假设**：
|条件|结果|
|:-:|:-:|
|特征值有足够的信息量， 且有一类很好的函数|这能保证低误差|
|有大量的训练数据集|这能保证得到更多的方差值|

